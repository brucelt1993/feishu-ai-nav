"""
èŠå¤©æœåŠ¡
æ•´åˆ OpenAI API å’Œ MCP Tools
"""

import json
from collections import defaultdict
from typing import Any

from loguru import logger
from openai import AsyncOpenAI

from app.config import settings
from app.llm.mcp_tools import get_tools
from app.llm.prompt_manager import get_system_prompt
from app.llm.tool_executor import ToolExecutor


class ChatService:
    """èŠå¤©æœåŠ¡"""

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
        )
        self.tool_executor = ToolExecutor()
        # å¯¹è¯å†å² (æŒ‰ç”¨æˆ·éš”ç¦»)
        self._conversations: dict[str, list[dict]] = defaultdict(list)

    async def chat(
        self,
        user_id: str,
        message: str,
        chat_id: str = "",
    ) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›å›å¤

        Args:
            user_id: ç”¨æˆ· ID
            message: ç”¨æˆ·æ¶ˆæ¯
            chat_id: ä¼šè¯ ID (ç¾¤èŠ ID æˆ–ç§èŠæ ‡è¯†)

        Returns:
            å›å¤æ–‡æœ¬æˆ–å¡ç‰‡ JSON
        """
        # è·å–å¯¹è¯å†å²
        conversation_key = f"{user_id}:{chat_id}"
        history = self._conversations[conversation_key]

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        history.append({"role": "user", "content": message})

        # ä¿æŒä¸Šä¸‹æ–‡çª—å£
        if len(history) > settings.max_context_messages * 2:
            history = history[-(settings.max_context_messages * 2) :]
            self._conversations[conversation_key] = history

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": get_system_prompt()},
            *history,
        ]

        try:
            # è°ƒç”¨ OpenAI API
            response = await self._call_openai(messages)

            # ä¿å­˜åŠ©æ‰‹å›å¤
            history.append({"role": "assistant", "content": response})

            return response

        except Exception as e:
            logger.error(f"âŒ OpenAI API è°ƒç”¨å¤±è´¥: {e}")
            import traceback
            logger.error(f"å †æ ˆ: {traceback.format_exc()}")
            raise

    async def _call_openai(self, messages: list[dict]) -> str:
        """
        è°ƒç”¨ OpenAI APIï¼Œæ”¯æŒ Function Calling
        """
        logger.info(f"ğŸ“¤ è°ƒç”¨ OpenAI, base_url={settings.openai_base_url}, model={settings.openai_model}, æ¶ˆæ¯æ•°={len(messages)}")

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆå¸¦å·¥å…·ï¼‰
        response = await self.client.chat.completions.create(
            model=settings.openai_model,
            messages=messages,
            tools=get_tools(),
            tool_choice="auto",
            max_tokens=settings.openai_max_tokens,
            temperature=settings.openai_temperature,
        )

        # è¯¦ç»†æ‰“å°å“åº”
        logger.info(f"ğŸ“¥ OpenAI åŸå§‹å“åº”: id={response.id}, model={response.model}, "
                    f"choicesæ•°={len(response.choices) if response.choices else 0}, "
                    f"usage={response.usage}")
        if response.choices:
            for i, choice in enumerate(response.choices):
                logger.info(f"ğŸ“¥ choice[{i}]: finish_reason={choice.finish_reason}, "
                           f"content={choice.message.content[:100] if choice.message.content else None}..., "
                           f"tool_calls={len(choice.message.tool_calls) if choice.message.tool_calls else 0}ä¸ª")

        # å¦‚æœå¸¦å·¥å…·çš„è¯·æ±‚è¿”å›ç©º choicesï¼Œå°è¯•ä¸å¸¦å·¥å…·é‡è¯•
        if not response.choices:
            logger.warning("âš ï¸ å¸¦å·¥å…·è¯·æ±‚è¿”å›ç©º choicesï¼Œå°è¯•ä¸å¸¦å·¥å…·é‡è¯•...")
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=messages,
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature,
            )
            logger.info(f"ğŸ“¥ é‡è¯•å“åº”: choicesæ•°={len(response.choices) if response.choices else 0}")

            if not response.choices:
                logger.error(f"âŒ OpenAI è¿”å›ç©º choices: {response}")
                return "æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶æ— æ³•å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚"

            # ä¸å¸¦å·¥å…·ï¼Œç›´æ¥è¿”å›
            return response.choices[0].message.content or ""

        assistant_message = response.choices[0].message

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if assistant_message.tool_calls:
            logger.info(f"ğŸ”§ è§¦å‘å·¥å…·è°ƒç”¨: {len(assistant_message.tool_calls)} ä¸ª")
            for tc in assistant_message.tool_calls:
                logger.info(f"ğŸ”§ å·¥å…·: {tc.function.name}, å‚æ•°: {tc.function.arguments}")

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_results = await self._execute_tools(assistant_message.tool_calls)

            # æ„å»ºå¸¦å·¥å…·ç»“æœçš„æ¶ˆæ¯
            messages.append(assistant_message.model_dump())
            messages.extend(tool_results)

            # ç¬¬äºŒæ¬¡è°ƒç”¨ (å¸¦å·¥å…·ç»“æœ)
            logger.debug(f"ğŸ“¤ ç¬¬äºŒæ¬¡è°ƒç”¨ OpenAI, æ¶ˆæ¯æ•°: {len(messages)}")
            second_response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=messages,
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature,
            )

            logger.info(f"ğŸ“¥ ç¬¬äºŒæ¬¡å“åº”: choicesæ•°={len(second_response.choices) if second_response.choices else 0}, "
                       f"usage={second_response.usage}")
            if second_response.choices:
                logger.info(f"ğŸ“¥ ç¬¬äºŒæ¬¡ content: {second_response.choices[0].message.content[:200] if second_response.choices[0].message.content else None}...")

            if not second_response.choices:
                logger.error(f"âŒ OpenAI ç¬¬äºŒæ¬¡è°ƒç”¨è¿”å›ç©º choices: {second_response}")
                return "æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶æ— æ³•å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚"

            return second_response.choices[0].message.content or ""

        # æ— å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›
        return assistant_message.content or ""

    async def _execute_tools(self, tool_calls: list) -> list[dict]:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœ
        """
        results = []

        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments or "{}")

            logger.info(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {function_name}, å‚æ•°: {function_args}")

            try:
                result = await self.tool_executor.execute(function_name, function_args)
                result_str = json.dumps(result, ensure_ascii=False, default=str)
            except Exception as e:
                logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                result_str = json.dumps({"error": str(e)}, ensure_ascii=False)

            results.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": result_str,
            })

        return results

    def clear_history(self, user_id: str, chat_id: str = ""):
        """æ¸…é™¤ç”¨æˆ·å¯¹è¯å†å²"""
        conversation_key = f"{user_id}:{chat_id}"
        self._conversations.pop(conversation_key, None)
